{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c96c0c7f71a92f2",
   "metadata": {},
   "source": [
    "# Twitter Mentions Stream\n",
    "\n",
    "This notebook listens to **X / Twitter’s public search endpoint** (via the\n",
    "[`twikit`](https://github.com/x0rz/twikit) async client) for brand‑related tweets\n",
    "and stores matches in the same `market_attention.duckdb` database used by our\n",
    "GDELT and RSS pipelines.\n",
    "\n",
    "## Why scrape Twitter?\n",
    "* Headlines tell us what *news desks* publish; tweets tell us what *people with\n",
    "  large followings* amplify in near‑real‑time.\n",
    "* By filtering for accounts with **≥ 10 k followers** we keep the focus on\n",
    "  tweets that can plausibly move sentiment.\n",
    "* Merging the resulting `ticker_mentions` with price data lets us explore\n",
    "  *attention shocks* vs. short‑term volatility.\n",
    "\n",
    "**Caveats**\n",
    "* Twitter rate‑limits unauthenticated search very aggressively. `twikit` works\n",
    "  by using the same guest‑token flow the web client uses, so if you hammer it\n",
    "  you will get 429 errors. The loop below handles that by sleeping until the\n",
    "  reset time.\n",
    "* For higher throughput you’ll need elevated API access or a paid tier.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0ebf6703e5f7fa",
   "metadata": {},
   "source": [
    "## Imports & configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "dd8142567b4a4ba4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T15:41:14.241809Z",
     "start_time": "2025-07-15T15:41:14.189844Z"
    }
   },
   "source": [
    "import asyncio\n",
    "import hashlib\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import nest_asyncio  # so await/async works smoothly in Jupyter\n",
    "from twikit import Client, TooManyRequests, errors\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Watch‑list (same as other notebooks)\n",
    "COMPANY_NAMES = {\n",
    "    \"Google\": \"GOOGL\",\n",
    "    \"Apple\": \"AAPL\",\n",
    "    \"Amazon\": \"AMZN\",\n",
    "    \"Nvidia\": \"NVDA\",\n",
    "    \"Microsoft\": \"MSFT\",\n",
    "    \"Bitcoin\": \"BTC\",\n",
    "    \"Ripple\": \"XRP\",\n",
    "}\n",
    "MIN_FOLLOWERS = 10_000\n",
    "QUERY = \" OR \".join(f'\"{kw}\"' for kw in COMPANY_NAMES)  # quoted OR‑joined terms\n",
    "print(\"Search query:\", QUERY)\n",
    "\n",
    "# DuckDB file (shared with other streams)\n",
    "DB_PATH = (Path.cwd().parent.parent / \"src\" / \"data\" / \"market_attention.duckdb\").resolve()\n",
    "DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "print(\"DB path:\", DB_PATH)\n",
    "\n",
    "# Ensure schema exists once at notebook load\n",
    "with duckdb.connect(DB_PATH) as con:\n",
    "    con.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS news_articles (\n",
    "            article_id TEXT PRIMARY KEY,\n",
    "            title TEXT,\n",
    "            timestamp TIMESTAMP\n",
    "        );\n",
    "        \"\"\"\n",
    "    )\n",
    "    con.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS ticker_mentions (\n",
    "            article_id TEXT,\n",
    "            ticker TEXT\n",
    "        );\n",
    "        \"\"\"\n",
    "    )\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query: \"Google\" OR \"Apple\" OR \"Amazon\" OR \"Nvidia\" OR \"Microsoft\" OR \"Bitcoin\" OR \"Ripple\"\n",
      "DB path: C:\\Users\\zaina\\PycharmProjects\\Market-Attention-Graph\\src\\data\\market_attention.duckdb\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "c8f817c910aef4b9",
   "metadata": {},
   "source": [
    "## Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57731c473267fd8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T22:52:34.204079Z",
     "start_time": "2025-07-14T22:52:34.186493Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def hash_id(text: str) -> str:\n",
    "    \"\"\"64‑char SHA‑256 hex digest (stable primary key).\"\"\"\n",
    "    return hashlib.sha256(text.encode()).hexdigest()\n",
    "\n",
    "\n",
    "async def authenticate() -> Client:\n",
    "    \"\"\"Return an authenticated **twikit** Client.\n",
    "\n",
    "    The call expects a `cookies.json` exported from a logged‑in browser session.\n",
    "    Remove or modify this step if you prefer guest‑token only.\n",
    "    \"\"\"\n",
    "    client = Client(language=\"en-US\")\n",
    "    client.load_cookies(\"cookies.json\")  # create once via browser dev‑tools\n",
    "    await client._get_guest_token()\n",
    "    return client\n",
    "\n",
    "\n",
    "async def latest_tweets(client: Client):\n",
    "    \"\"\"Fetch up to 100 newest tweets matching *QUERY* (web public search API).\"\"\"\n",
    "    try:\n",
    "        return await client.search_tweet(QUERY, \"Latest\", count=100)\n",
    "    except errors.NotFound:  # guest token expired → refresh & retry once\n",
    "        await client._get_guest_token()\n",
    "        return await client.search_tweet(QUERY, \"Latest\", count=100)\n",
    "\n",
    "\n",
    "def save_to_db(con: duckdb.DuckDBPyConnection, tweets):\n",
    "    \"\"\"Insert tweet rows + ticker mentions, skipping dups & small accounts.\"\"\"\n",
    "    added = 0\n",
    "    for tw in tweets:\n",
    "        if getattr(tw.user, \"followers_count\", 0) < MIN_FOLLOWERS:\n",
    "            continue\n",
    "\n",
    "        tweet_id = hash_id(tw.id)\n",
    "        title = tw.text\n",
    "        ts = datetime.strptime(tw.created_at, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "\n",
    "        mentions = [\n",
    "            tk\n",
    "            for name, tk in COMPANY_NAMES.items()\n",
    "            if name.lower() in title.lower() or tk.lower() in title.lower()\n",
    "        ]\n",
    "        if not mentions:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            con.execute(\"INSERT INTO news_articles VALUES (?, ?, ?)\", (tweet_id, title, ts))\n",
    "        except duckdb.ConstraintException:\n",
    "            continue  # duplicate\n",
    "\n",
    "        for tk in mentions:\n",
    "            con.execute(\"INSERT INTO ticker_mentions VALUES (?, ?)\", (tweet_id, tk))\n",
    "        added += 1\n",
    "    return added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20202c72915445d",
   "metadata": {},
   "source": [
    "## Continuous poll loop (every 20 s)\n",
    "*Handles 429 by sleeping until reset.* Stop with *Kernel → Interrupt*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479a33aef4ce0f3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T22:52:44.638082Z",
     "start_time": "2025-07-14T22:52:44.624081Z"
    }
   },
   "outputs": [],
   "source": [
    "async def poll_twitter(interval_seconds: int = 20):\n",
    "    con = duckdb.connect(DB_PATH)\n",
    "    client = await authenticate()\n",
    "    stored = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            tweets = await latest_tweets(client)\n",
    "        except TooManyRequests as e:\n",
    "            reset = datetime.fromtimestamp(e.rate_limit_reset)\n",
    "            wait = max(1, int((reset - datetime.utcnow()).total_seconds()))\n",
    "            print(f\"[{datetime.utcnow()}] ⚠️ 429 hit → sleeping {wait}s (until {reset})\")\n",
    "            await asyncio.sleep(wait)\n",
    "            continue\n",
    "\n",
    "        if tweets:\n",
    "            n = save_to_db(con, tweets)\n",
    "            stored += n\n",
    "            print(f\"[{datetime.utcnow()}] +{n} tweets stored (total {stored})\")\n",
    "        else:\n",
    "            print(f\"[{datetime.utcnow()}] No tweets returned\")\n",
    "\n",
    "        await asyncio.sleep(interval_seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb840bcd5e131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "await poll_twitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1413ee070c36dcb",
   "metadata": {},
   "source": [
    "## Quick sanity‑check query"
   ]
  },
  {
   "cell_type": "code",
   "id": "3e72391889c7cfba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T23:10:56.551507Z",
     "start_time": "2025-07-14T23:10:56.487843Z"
    }
   },
   "source": [
    "con = duckdb.connect(DB_PATH)\n",
    "pd.set_option(\"display.max_rows\", None)  # show all when printing\n",
    "df = con.execute(\"SELECT title, timestamp, ticker FROM news_articles JOIN ticker_mentions ON article_id = article_id ORDER BY timestamp LIMIT 10\").fetchdf()\n",
    "pd.set_option('display.max_rows',    None)\n",
    "display(df)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               title           timestamp  \\\n",
       "0  The latest MLX Swift supports tvOS 📺 !\\n\\nYou ... 2025-07-15 01:55:08   \n",
       "1  That’s awful… if you’re the thief you should b... 2025-07-15 01:55:31   \n",
       "2  そうか両社共通の投資家Founders Fundが引き合わせた説はありうるな。ナプキンの裏計... 2025-07-15 01:55:51   \n",
       "3  @GrapeApe9k Just because drones require a smal... 2025-07-15 01:56:30   \n",
       "4  @pudgypenguins @Apple @Google @PlayPudgyParty ... 2025-07-15 01:56:31   \n",
       "5  @pudgypenguins @Apple @Google @PlayPudgyParty ... 2025-07-15 01:56:31   \n",
       "6  @namiru319 失礼いたします。Amazonの自動メッセージです。 ご注文は、お届け予... 2025-07-15 01:56:32   \n",
       "7  ε/ The cycle structure hasn’t changed\\n\\n• Bit... 2025-07-15 01:56:32   \n",
       "8  If you want to get early opportunities, you ca... 2025-07-15 01:56:34   \n",
       "9  This is not altseason.\\n\\nThis is still Bitcoi... 2025-07-15 01:56:34   \n",
       "\n",
       "  ticker  \n",
       "0   AAPL  \n",
       "1  GOOGL  \n",
       "2  GOOGL  \n",
       "3   AAPL  \n",
       "4   AAPL  \n",
       "5  GOOGL  \n",
       "6   AMZN  \n",
       "7    BTC  \n",
       "8    BTC  \n",
       "9    BTC  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The latest MLX Swift supports tvOS 📺 !\\n\\nYou ...</td>\n",
       "      <td>2025-07-15 01:55:08</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That’s awful… if you’re the thief you should b...</td>\n",
       "      <td>2025-07-15 01:55:31</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>そうか両社共通の投資家Founders Fundが引き合わせた説はありうるな。ナプキンの裏計...</td>\n",
       "      <td>2025-07-15 01:55:51</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@GrapeApe9k Just because drones require a smal...</td>\n",
       "      <td>2025-07-15 01:56:30</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@pudgypenguins @Apple @Google @PlayPudgyParty ...</td>\n",
       "      <td>2025-07-15 01:56:31</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@pudgypenguins @Apple @Google @PlayPudgyParty ...</td>\n",
       "      <td>2025-07-15 01:56:31</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@namiru319 失礼いたします。Amazonの自動メッセージです。 ご注文は、お届け予...</td>\n",
       "      <td>2025-07-15 01:56:32</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ε/ The cycle structure hasn’t changed\\n\\n• Bit...</td>\n",
       "      <td>2025-07-15 01:56:32</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If you want to get early opportunities, you ca...</td>\n",
       "      <td>2025-07-15 01:56:34</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is not altseason.\\n\\nThis is still Bitcoi...</td>\n",
       "      <td>2025-07-15 01:56:34</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "1903663214f00051",
   "metadata": {},
   "source": [
    "### Mention count\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "48d965024718a9e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T23:11:08.807623Z",
     "start_time": "2025-07-14T23:11:08.780106Z"
    }
   },
   "source": [
    "df = con.execute(\"SELECT ticker, COUNT(ticker) AS mentions FROM ticker_mentions GROUP BY ticker ORDER BY mentions\").fetchdf()\n",
    "con.close()\n",
    "display(df)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  ticker  mentions\n",
       "0   AMZN         1\n",
       "1  GOOGL         3\n",
       "2    BTC         3\n",
       "3   AAPL         5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BTC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
